{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_le_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorTFromK/GoogleSpeechCommandClassifier/blob/master/train_le_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL5L789XY-Qb",
        "cellView": "code"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "FILE_DIR_MAIN = \"/content/google_speech_command/\"\n",
        "FILE_DIR_GRIDSEARCH = \"/content/google_speech_command/gridsearch/\"\n",
        "FILE_DIR_TRAIN = FILE_DIR_MAIN + \"train/\"\n",
        "FILE_DIR_TEST = FILE_DIR_MAIN + \"test/\"\n",
        "FILE_DIR_EVAL = FILE_DIR_MAIN + \"eval/\"\n",
        "\n",
        "# Hyperparameter for model optimization\n",
        "NUM_DENSE_LAYER = 1\n",
        "NUM_NEURONS = [64, 128, 256]\n",
        "NUM_MEL_BINS = [64, 96]\n",
        "DROPOUT_RATE = [0.2, 0.3, 0.4]\n",
        "LEARNING_RATE = [0.01, 0.001]\n",
        "TRAININGS_EPOCHS = [32, 64, 128]\n",
        "BATCH_SIZE = [30, 50]\n",
        "\n",
        "class LeNet():\n",
        "  def __init__(self, num_dense_layer, num_hidden_neurons, num_mel_bins, dropout_rate,\n",
        "               learning_rate, input_size):\n",
        "    self.num_dense_layer = num_dense_layer\n",
        "    self.num_hidden_neurons = num_hidden_neurons\n",
        "    self.num_mel_bins = num_mel_bins\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.learning_rate = learning_rate\n",
        "    self.input_size = input_size\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3LkV9GvNPS4"
      },
      "source": [
        "# **Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16q3LBIe8snz"
      },
      "source": [
        "# computes log mel spectrogram\n",
        "def stft_and_log_mel_spectrogram(x, sampling_rate: int, num_mel_spects: int, \n",
        "                                  window_size: int, hop_size: int):\n",
        "  \n",
        "  stfts = tf.signal.stft(x, frame_length=window_size, frame_step=hop_size, fft_length=window_size)\n",
        "  spectrograms = tf.abs(stfts)\n",
        "\n",
        "  # Warp the linear scale spectrograms into the mel-scale.\n",
        "  num_spectrogram_bins = stfts.shape[-1]\n",
        "  lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0, sampling_rate / 2, num_mel_spects\n",
        "  linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "    num_mel_bins, num_spectrogram_bins, sampling_rate, lower_edge_hertz,\n",
        "    upper_edge_hertz)\n",
        "  mel_spectrograms = tf.tensordot(\n",
        "    spectrograms, linear_to_mel_weight_matrix, 1)\n",
        "  mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n",
        "    linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "  # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
        "  log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "  return tf.reshape(log_mel_spectrograms, shape=[-1, log_mel_spectrograms.shape[1], num_mel_spects, 1])\n",
        "\n",
        "# creates model \n",
        "def create_model(leNet: LeNet):\n",
        "  inputs = keras.Input(shape= leNet.input_size, dtype=tf.float32)\n",
        "  log_mel_spec = keras.layers.Lambda(stft_and_log_mel_spectrogram, arguments={\n",
        "      'sampling_rate': 16000, 'num_mel_spects': leNet.num_mel_bins, \n",
        "      'window_size': 1024, 'hop_size': 512\n",
        "  })(inputs)\n",
        "  conv_1 = keras.layers.Conv2D(filters=8, kernel_size=(3, 3), padding=\"same\")(log_mel_spec)\n",
        "  batch_1 = keras.layers.BatchNormalization(axis=3)(conv_1)\n",
        "  activation_1 = keras.layers.Activation('relu')(batch_1)\n",
        "  pool_1 = keras.layers.MaxPooling2D(pool_size=(3, 2))(activation_1)\n",
        "\n",
        "  conv_2 = keras.layers.Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\")(pool_1)\n",
        "  batch_2 = keras.layers.BatchNormalization(axis=3)(conv_2)\n",
        "  activation_2 = keras.layers.Activation('relu')(batch_2)\n",
        "  pool_2 = keras.layers.MaxPooling2D(pool_size=(3, 2))(activation_2)\n",
        "\n",
        "  conv_3 = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\")(pool_2)\n",
        "  activation_3 = keras.layers.Activation('relu')(conv_3)\n",
        "  batch_3 = keras.layers.BatchNormalization(axis=3)(activation_3)\n",
        "\n",
        "  dropout = keras.layers.Dropout(leNet.dropout_rate)(batch_3)\n",
        "  flatten = keras.layers.Flatten()(dropout)\n",
        "  layer_list = []\n",
        "  layer_list.append(keras.layers.Dense(leNet.num_hidden_neurons[0], activation=\"relu\")(flatten))\n",
        "  layer_list.append(keras.layers.Dropout(rate=leNet.dropout_rate)(layer_list[-1]))\n",
        "\n",
        "# Fully connected layer\n",
        "  for x in range(1, leNet.num_dense_layer - 1):\n",
        "    layer_list.append(keras.layers.Dense(leNet.num_hidden_neurons[x], activation=\"relu\")(\n",
        "    layer_list[-1]))  \n",
        "    layer_list.append(keras.layers.Dropout(rate=leNet.dropout_rate)(layer_list[-1]))\n",
        "  if leNet.num_dense_layer != 1:\n",
        "    layer_list.append(keras.layers.Dense(leNet.num_hidden_neurons[-1], activation=\"relu\")(layer_list[-1]))\n",
        "    layer_list.append(keras.layers.Dropout(rate=leNet.dropout_rate)(layer_list[-1]))\n",
        "\n",
        "    predictions = keras.layers.Dense(leNet.prediction_classes, activation=\"softmax\")(layer_list[-1])  # Classification layer or output layer\n",
        "\n",
        "    adam = keras.optimizers.Adam(learning_rate=leNet.learning_rate)\n",
        "    model = keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy',metrics=[keras.metrics.TruePositives(), keras.metrics.Precision(), \"accuracy\"])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z5LEdkm830K"
      },
      "source": [
        "def train_model():\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-URFSZXd9Ql7"
      },
      "source": [
        "def test_model():\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeO0ouPMAuap"
      },
      "source": [
        "def long_op():\n",
        "  for x in range(1000):\n",
        "    time.sleep(2.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD5c3BeGhewT"
      },
      "source": [
        "def write_file_test(filename:str):\n",
        "  with open(filename, 'w') as writefile:\n",
        "    for x in range(10):\n",
        "      writefile.write(\"Line: {:d}\\n\".format(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRjFFDsP5ejH"
      },
      "source": [
        "def read_file_test(filename: str):\n",
        "  with open(filename, 'r') as readfile:\n",
        "    for line in readfile:\n",
        "      print(line)"
      ],
      "execution_count": 103,
      "outputs": []
    }
  ]
}